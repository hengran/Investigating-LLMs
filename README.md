# Investigating-retrieval-augmentation-LLMs-
## investigating LLMs
+ **Evaluating the Factual Consistency of Large Language Models Through News Summarization** [[paper](https://aclanthology.org/2023.findings-acl.322.pdf)] 2023, ACL findings
+ **Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent** [[paper](https://arxiv.org/pdf/2304.09542.pdf)] 2023.4
## investigating LLMs with restrieval augmentation
+  **Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu., et.al: Investigating the Factual Knowledge Boundary of Large Language Models
with Retrieval Augmentation** [[paper]](https://arxiv.org/abs/2305.13300) 2023.7
+ **Jian Xie, Kai Zhang, Kai Zhang, Renze Lou, Yu Su:Adaptive Chameleon or Stubborn Sloth: REVEALING THE BEHAVIOR OF LARGE LANGUAGE MODELS IN KNOWLEDGE CONFLICTS**  [[paper]](https://browse.arxiv.org/pdf/2305.13300.pdf) 2023.10
+ **Giwon Hong, Jeonghwan Kim, Junmo Kang, Sung-Hyon Myaeng, Joyce Jiyoung Whang: Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators**  [[paper]](https://browse.arxiv.org/pdf/2305.01579.pdf) 2023.5
+ **Jiawei Chen, Hongyu Lin, Xianpei Han, Le Su: Benchmarking Large Language Models in Retrieval-Augmented Generation** [[paper]](https://browse.arxiv.org/pdf/2305.01579.pdf) 2023.9 
+ **Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, Hannaneh Hajishirzi: When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories** [[paper]](https://aclanthology.org/2023.acl-long.546.pdf) 2023, ACL long
+ **Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo, Hao Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, Hang Li: Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment** [[paper](https://arxiv.org/abs/2308.05374)] 2023.08
+ **Siqing Huo, Negar Arabzadeh, Charles L. A. Clarke: Retrieving Supporting Evidence for Generative Question**  [[paper]](https://arxiv.org/pdf/2309.11392.pdf) 2023.09
+ **Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, Scott Wen-tau Yih: Trusting Your Evidence: Hallucinate Less with Context-aware Decoding** [[paper]](https://arxiv.org/abs/2305.14739) 2023.05
